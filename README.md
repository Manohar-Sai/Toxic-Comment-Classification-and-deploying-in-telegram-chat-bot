# Toxic-Comment-Classification-and-deploying-in-telegram-chat-bot

The Internet feels to be a safe place as there is no true identity that needs to be
provided and no face to face confrontation. This is misused by many people
throughout the world which makes them enjoy bullying others. Toxic comments
sure have reached peaks in recent years due to advancement in social media
(apps). This may be an enjoyment for some but also is leading to a threat of life
for some. 

This is the main motivation for coming up with the idea of this project.

### Problem Definition
Given a group of sentences used as a part of commenting in online platforms,
classify it as toxic or not. Toxicity of a comment can be presented in several
categories - toxic, severe-toxic, obscene, threat, insult or identity-hate. Problem
statement needs to classify it as either toxic or not and then classify the
comment to which category(ies) it belongs to.

### Modelling
Modelling and Evaluation
- Multinomial Naive Bayes
- Logistic Regression
- Linear SVC
- LSTM


Dataset link here
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data
